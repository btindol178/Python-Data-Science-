{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import sklearn  \n",
    "# First we need to split data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top-Left</th>\n",
       "      <th>Top-Middle</th>\n",
       "      <th>Top-Right</th>\n",
       "      <th>Middle-Left</th>\n",
       "      <th>Middle-Middle</th>\n",
       "      <th>Middle-Right</th>\n",
       "      <th>Bottom-Left</th>\n",
       "      <th>Bottom-Middle</th>\n",
       "      <th>Bottom-Right</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Top-Left Top-Middle Top-Right Middle-Left Middle-Middle Middle-Right  \\\n",
       "0        x          x         x           x             o            o   \n",
       "1        x          x         x           x             o            o   \n",
       "2        x          x         x           x             o            o   \n",
       "3        x          x         x           x             o            o   \n",
       "4        x          x         x           x             o            o   \n",
       "\n",
       "  Bottom-Left Bottom-Middle Bottom-Right     Class  \n",
       "0           x             o            o  positive  \n",
       "1           o             x            o  positive  \n",
       "2           o             o            x  positive  \n",
       "3           o             b            b  positive  \n",
       "4           b             o            b  positive  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic_tac_toe = pd.read_csv(\"tic-tac-toe.csv\")\n",
    "tic_tac_toe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two samples\n",
    "After building several classification models based on thetic_tac_toe dataset, you realize that some models do not generalize as well as others. You have created training and testing splits just as you have been taught, so you are curious why your validation process is not working.\n",
    "\n",
    "After trying a different training, test split, you noticed differing accuracies for your machine learning model. Before getting too frustrated with the varying results, you have decided to see what else could be going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "positive    134\n",
      "negative     66\n",
      "Name: Class, dtype: int64\n",
      "positive    123\n",
      "negative     77\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create two different samples of 200 observations \n",
    "sample1 = tic_tac_toe.sample(200, random_state=1111)\n",
    "sample2 = tic_tac_toe.sample(200, random_state=1171)\n",
    "\n",
    "# Print the number of common observations \n",
    "print(len([index for index in sample1.index if index in sample2.index]))\n",
    "\n",
    "# Print the number of observations in the Class column\n",
    "print(sample1['Class'].value_counts())\n",
    "print(sample2['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn's KFold()\n",
    "You just finished running a colleagues code that creates a random forest model and calculates an out-of-sample accuracy. You noticed that your colleague's code did not have a random state, and the errors you found were completely different than the errors your colleague reported.\n",
    "\n",
    "To get a better estimate for how accurate this random forest model will be on new data, you have decided to generate some indices to use for KFold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables using pandas\n",
    "X = pd.get_dummies(tic_tac_toe.iloc[:, 0:9]) # first 9 columns get dummy variables\n",
    "y = tic_tac_toe.iloc[:, 9] # make class column prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training indices: 766\n",
      "Number of validation indices: 192\n",
      "Number of training indices: 766\n",
      "Number of validation indices: 192\n",
      "Number of training indices: 766\n",
      "Number of validation indices: 192\n",
      "Number of training indices: 767\n",
      "Number of validation indices: 191\n",
      "Number of training indices: 767\n",
      "Number of validation indices: 191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "# Use KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1111)\n",
    "\n",
    "# Create splits\n",
    "splits = kf.split(X)\n",
    "\n",
    "# Print the number of indices\n",
    "for train_index, val_index in splits:\n",
    "    print(\"Number of training indices: %s\" % len(train_index))\n",
    "    print(\"Number of validation indices: %s\" % len(val_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing datasets. Use 10% for the test set\n",
    "#X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.10, random_state=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create two holdout sets\n",
    "You recently created a simple random forest model to predict Tic-Tac-Toe game wins for your boss, and at her request, you did not do any parameter tuning. Unfortunately, the overall model accuracy was too low for her standards. This time around, she has asked you to focus on model performance.\n",
    "\n",
    "Before you start testing different models and parameter sets, you will need to split the data into training, validation, and testing datasets. Remember that after splitting the data into training and testing datasets, the validation dataset is created by splitting the training dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary training and final testing datasets\n",
    "X_temp, X_test, y_temp, y_test  =\\\n",
    "    train_test_split(X, y, test_size=0.20, random_state=1111)\n",
    "\n",
    "# Create the final training and validation datasets\n",
    "X_train, X_val, y_train, y_val  =\\\n",
    "    train_test_split(X_temp, y_temp, test_size=0.25, random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_features=4, n_informative=2,\n",
    "                        random_state=0, shuffle=False)\n",
    "\n",
    "rfc = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
    "\n",
    "# Access the training and validation indices of splits\n",
    "for train_index, val_index in splits:\n",
    "    # Setup the training and validation data\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_val, y_val = X[val_index], y[val_index]\n",
    "    # Fit the random forest model\n",
    "    rfc.fit(X_train, y_train)\n",
    "    # Make predictions, and print the accuracy\n",
    "    predictions = rfc.predict(X_val)\n",
    "    print(\"Split accuracy: \" + str(mean_squared_error(y_val, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split accuracy: 178.75586448813047 <br>\n",
    "Split accuracy: 98.29560208158634<br>\n",
    "Split accuracy: 86.2673010849621<br>\n",
    "Split accuracy: 217.4185114496197<br>\n",
    "Split accuracy: 140.5437661156536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instruction 1: Load the cross-validation method\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Instruction 2: Load the random forest regression model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instruction 3: Load the mean squared error method\n",
    "# Instruction 4: Load the function for creating a scorer\n",
    "from sklearn.metrics import mean_squared_error, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement cross_val_score()\n",
    "Your company has created several new candies to sell, but they are not sure if they should release all five of them. To predict the popularity of these new candies, you have been asked to build a regression model using the candy dataset. Remember that the response value is a head-to-head win-percentage against other candies.\n",
    "\n",
    "Before you begin trying different regression models, you have decided to run cross-validation on a simple random forest model to get a baseline error to compare with any future results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146.70226291353532\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestRegressor(n_estimators=25, random_state=1111)\n",
    "mse = make_scorer(mean_squared_error)\n",
    "\n",
    "# Set up cross_val_score\n",
    "cv = cross_val_score(estimator=rfc,\n",
    "                     X=X_train,\n",
    "                     y=y_train,\n",
    "                     cv=10,\n",
    "                     scoring=make_scorer(mean_squared_error))\n",
    "\n",
    "# Print the mean error\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-one-out-cross-validation\n",
    "Let's assume your favorite candy is not in the candy dataset, and that you are interested in the popularity of this candy. Using 5-fold cross-validation will train on only 80% of the data at a time. The candy dataset only has 85 rows though, and leaving out 20% of the data could hinder our model. However, using leave-one-out-cross-validation allows us to make the most out of our limited dataset and will give you the best estimate for your favorite candy's popularity!\n",
    "\n",
    "In this exercise, you will use cross_val_score() to perform LOOCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the errors is: 6.205277042202404.\n",
      "The standard deviation of the errors is: 6.161787614306969.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "\n",
    "# Create scorer\n",
    "mae_scorer = make_scorer(mean_absolute_error)\n",
    "\n",
    "rfr = RandomForestRegressor(n_estimators=15, random_state=1111)\n",
    "\n",
    "# Implement LOOCV\n",
    "scores = cross_val_score(rfr, X=X, y=y, cv=y.shape[0], scoring=mae_scorer)\n",
    "\n",
    "# Print the mean and standard deviation\n",
    "print(\"The mean of the errors is: %s.\" % np.mean(scores))\n",
    "print(\"The standard deviation of the errors is: %s.\" % np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "Creating Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 15, 'n_jobs': None, 'oob_score': False, 'random_state': 1111, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Review the parameters of rfr\n",
    "print(rfr.get_params())\n",
    "\n",
    "# Maximum Depth\n",
    "max_depth = [4, 8, 12]\n",
    "\n",
    "# Minimum samples for a split\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Max features \n",
    "max_features = [4, 6, 8, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a model using ranges\n",
    "You have just finished creating a list of hyperparameters and ranges to use when tuning a predictive model for an assignment. You have used max_depth, min_samples_split, and max_features as your range variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'mse', 'max_depth': 8, 'max_features': 6, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import random\n",
    "\n",
    "# Fill in rfr using your variables\n",
    "rfr = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=random.choice(max_depth),\n",
    "    min_samples_split=random.choice(min_samples_split),\n",
    "    max_features=random.choice(max_features))\n",
    "\n",
    "# Print out the parameters\n",
    "print(rfr.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized search CV \n",
    "Preparing for RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# Finish the dictionary by adding the max_depth parameter\n",
    "param_dist = {\"max_depth\": [2, 4, 6, 8],\n",
    "              \"max_features\": [2, 4, 6, 8, 10],\n",
    "              \"min_samples_split\": [2, 4, 8, 16]}\n",
    "\n",
    "# Create a random forest regression model\n",
    "rfr = RandomForestRegressor(n_estimators=10, random_state=1111)\n",
    "\n",
    "# Create a scorer to use (use the mean squared error)\n",
    "scorer = make_scorer(mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing RandomizedSearchCV <br>\n",
    "You are hoping that using a random search algorithm will help you improve predictions for a class assignment. You professor has challenged your class to predict the overall final exam average score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables using pandas\n",
    "X = pd.get_dummies(tic_tac_toe.iloc[:, 0:9]) # first 9 columns get dummy variables\n",
    "y = tic_tac_toe.iloc[:, 9] # make class column prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the method for random search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Build a random search using param_dist, rfr, and scorer\n",
    "random_search =\\\n",
    "    RandomizedSearchCV(\n",
    "        estimator=rfr,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=10,\n",
    "        cv=5,\n",
    "        scoring=scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, make_scorer\n",
    "\n",
    "# Create a precision scorer\n",
    "precision = make_scorer(precision_score)\n",
    "# Finalize the random search\n",
    "rs = RandomizedSearchCV(\n",
    "  estimator=rfr, param_distributions=param_dist,\n",
    "  scoring = precision,\n",
    "  cv=5, n_iter=10, random_state=1111)\n",
    "rs.fit(X, y)\n",
    "\n",
    "# print the mean test scores:\n",
    "print('The accuracy for each run was: {}.'.format(rs.cv_results_['mean_test_score']))\n",
    "# print the best model score:\n",
    "print('The best accuracy for a single model was: {}'.format(rs.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  The accuracy for each run was: <br>[0.86446668 0.75302055 0.67570816.88459939 0.88381178 0.86917588 0.68014695 0.81721906 0.87895856 0.92917474]. <br>\n",
    "    The best accuracy for a single model was: 0.9291747446879924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
