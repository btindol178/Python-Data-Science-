{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " from textblob import TextBlob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = TextBlob(\"Blake tindol cannot figure out how to pass a csv file to Text blob. This is a problem for blake because he wants to learn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/cloudera/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# part of speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Blake', 'NNP'),\n",
       " ('tindol', 'NN'),\n",
       " ('can', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('figure', 'VB'),\n",
       " ('out', 'RP'),\n",
       " ('how', 'WRB'),\n",
       " ('to', 'TO'),\n",
       " ('pass', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('csv', 'NN'),\n",
       " ('file', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('Text', 'NNP'),\n",
       " ('blob', 'NN'),\n",
       " ('This', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('problem', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('blake', 'NN'),\n",
       " ('because', 'IN'),\n",
       " ('he', 'PRP'),\n",
       " ('wants', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('learn', 'VB')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of non phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/cloudera/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WordList(['blake', 'csv file', 'text'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "wiki.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Sentiment(polarity=0.39166666666666666, subjectivity=0.4357142857142857)\n",
      "Polarity: 0.392. Subjectivity: 0.436\n",
      "Polarity: 0.392\n",
      "Sentiment assessments: Sentiment(polarity=0.39166666666666666, subjectivity=0.4357142857142857, assessments=[(['amazingly', 'simple'], 0.0, 0.35714285714285715, None), (['great'], 0.8, 0.75, None), (['fun', '!'], 0.375, 0.2, None)])\n"
     ]
    }
   ],
   "source": [
    "testimonial = TextBlob(\"Textblob is amazingly simple to use. What great fun!\")\n",
    "print(\"Sentiment: {}\".format(testimonial.sentiment))\n",
    "print(\"Polarity: {0:.3f}. Subjectivity: {1:.3f}\".format(testimonial.sentiment[0], testimonial.sentiment[1]))\n",
    "print(\"Polarity: {0:.3f}\".format(testimonial.sentiment.polarity))\n",
    "print(\"Sentiment assessments: {}\".format(testimonial.sentiment_assessments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1.4) Tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "zen = TextBlob(\"Blake is cool. \"\n",
    "                \"Melina is cooler. \"\n",
    "                \" complex not cool.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Blake', 'is', 'cool', 'Melina', 'is', 'cooler', 'complex', 'not', 'cool'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting words\n",
    "zen.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Blake is cool.\"),\n",
       " Sentence(\"Melina is cooler.\"),\n",
       " Sentence(\"complex not cool.\")]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting sentences\n",
    "zen.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.35, subjectivity=0.65)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "Sentiment(polarity=-0.2375, subjectivity=0.525)\n"
     ]
    }
   ],
   "source": [
    "# Sentence-level sentiment.\n",
    "for sentence in zen.sentences:\n",
    "    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words inflection lemmatization and stemming\n",
    "\n",
    "Each word in TextBlob.words or Sentence.words is a Word object, which is a subclass of unicode, with useful methods.\n",
    "\n",
    "Words Inflection refers to a process of word formation from its base form into a word in a different grammatical category, such as tense, case, voice, aspect, person, mood, etc. Examples are \"bus\" --> \"buses\", \"party\" --> \"parties\", \"ride\" --> \"riding\", \"Paul\" --> \"Paul's\", \"Him\" --> \"Himself\", \"Smart\" --> \"Smarter\".\n",
    "\n",
    "Words Lemmatization usually refers to a process to reduce inflectional forms of a word into the base dictionary form known as lemma. This is slightly different from stemming, where stemming chops off the ends of words hoping to reduce inflectional forms into the common root. This common root may not be a dictionary word. For example, \"argument\", \"arguing\" and \"argues\" are all reduced into \"argu\" in stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['The', 'test', 'tomorrow', 'scares', 'me'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = TextBlob('The test tomorrow scares me')\n",
    "sentence.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tomorrow'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Singularize the 3rd word.\n",
    "sentence.words[2].singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pluralize the last word.\n",
    "sentence.words[-1].pluralize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet Integration\n",
    "\n",
    "Note:\n",
    "The synsets property returns a list of Synset objects for the word. In other words, it basically is a set of words or phrases that are roughly synonymous. Synsets include simplex words and collocations, such as \"play around\" and \"car pools\".\n",
    "\n",
    "Each synset has three parts: <word>.<pos>.<number>, where <word> is the word, <pos> is the part-of-speech of the word, <number> is the index of the sense. The sense aspect denotes the different usages of the word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/cloudera/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Synset('octopus.n.01'), Synset('octopus.n.02')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from textblob import Word\n",
    "from textblob.wordnet import VERB\n",
    "word = Word(\"octopus\")\n",
    "word.synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a collection of facts from which conclusions may be drawn',\n",
       " 'an item of factual information derived from measurement or research']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word definitions\n",
    "Word(\"data\").definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chop.v.05'),\n",
       " Synset('hack.v.02'),\n",
       " Synset('hack.v.03'),\n",
       " Synset('hack.v.04'),\n",
       " Synset('hack.v.05'),\n",
       " Synset('hack.v.06'),\n",
       " Synset('hack.v.07'),\n",
       " Synset('hack.v.08')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"hack\").get_synsets(pos=VERB)\n",
    "#Note: the number at the end (called sense) corresponds to the different meanings shown by the definitions property. For example, \"hack.v.03\" corresponds to the third definitoon of the word hack (i.e., \"a tool (as a hoe or pick or mattock) used for breaking up the surface of the soil'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he hacked his way through the forest']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synset('hack.v.03').examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zh-CN'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"他是好人\").detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"做\").get_synsets(pos=VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'do'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"做\").translate(from_lang=\"zh-CN\", to=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He is a good person'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"他是好人\").translate(from_lang=\"zh-CN\", to=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我必须大便'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(\"I have to go poop\").translate(from_lang=\"en\", to=\"zh-CN\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1111111111111111"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word similarity\n",
    "from textblob.wordnet import Synset\n",
    "octopus = Synset('octopus.n.02')\n",
    "shrimp = Synset('shrimp.n.03')\n",
    "octopus.path_similarity(shrimp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chop = Synset('chop.v.05')\n",
    "hack05 = Synset('hack.v.02')\n",
    "chop.path_similarity(hack05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['cat', 'dog', 'octopus'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting words in text\n",
    "animals = TextBlob(\"cat dog octopus\")\n",
    "animals.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['cats', 'dogs', 'octopodes'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pluralize words\n",
    "animals.words.pluralize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have good spelling!\n"
     ]
    }
   ],
   "source": [
    "# Spelling correction\n",
    "b = TextBlob(\"I havv goode speling!\")\n",
    "print(b.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spirit', 0.6788617886178862),\n",
       " ('shirt', 0.2032520325203252),\n",
       " ('skirt', 0.06910569105691057),\n",
       " ('sport', 0.028455284552845527),\n",
       " ('spit', 0.008130081300813009),\n",
       " ('spire', 0.008130081300813009),\n",
       " ('spilt', 0.0040650406504065045)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show a list of possible words\n",
    "from textblob import Word\n",
    "w = Word('spirt')\n",
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate word frequency\n",
    "monty = TextBlob(\"We are no longer the Knights who say Ni. \"\n",
    "                     \"We are now the Knights who say Ekki ekki ekki PTANG.\")\n",
    "monty.word_counts['ekki']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way to calculate word frequency\n",
    "monty.words.count('longer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty.words.count('ekki', case_sensitive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.noun_phrases.count('python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation and language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"簡單勝於復雜。\")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_blob = TextBlob(u'Simple is better than complex.')\n",
    "en_blob.translate(to = \"zh-TW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Simple, c'est mieux que complexe.\")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_blob.translate(to = \"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"简单胜于复杂。\")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_blob.translate(to = \"zh-CN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Simple is better than complex\")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_blob = TextBlob(u\"簡單比複雜更好\")\n",
    "chinese_blob.translate(from_lang=\"zh-TW\", to=\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing, indexing and n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And/CC/O/O now/RB/B-ADVP/O for/IN/B-PP/B-PNP sometghing/VBG/B-VP/I-PNP completely/RB/B-ADJP/O different/JJ/I-ADJP/O ././O/O\n"
     ]
    }
   ],
   "source": [
    "b = TextBlob(\"And now for sometghing completely different.\")\n",
    "print(b.parse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Blake is cool. Meli\")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen[0:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.find(\"Simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"apples and bananas\")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_blob = TextBlob('apples')\n",
    "banana_blob = TextBlob('bananas')\n",
    "apple_blob + ' and ' + banana_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apples and bananas'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{0} and {1}\".format(apple_blob, banana_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Now', 'is', 'better']),\n",
       " WordList(['is', 'better', 'than']),\n",
       " WordList(['better', 'than', 'never'])]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n-grams\n",
    "blob = TextBlob(\"Now is better than never.\")\n",
    "blob.ngrams(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"I like to aet to.\")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"I liek to aet tuo.\").correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "\n",
    "train = [\n",
    "('I love this sandwich.', 'pos'),\n",
    "('this is an amazing place!', 'pos'),\n",
    "('I feel very good about these beers.', 'pos'),\n",
    "('this is my best work.', 'pos'),\n",
    "(\"what an awesome view\", 'pos'),\n",
    "('I do not like this restaurant', 'neg'),\n",
    "('I am tired of this stuff.', 'neg'),\n",
    "(\"I can't deal with this\", 'neg'),\n",
    "('he is my sworn enemy!', 'neg'),\n",
    "('my boss is horrible.', 'neg')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "\n",
    "test = [\n",
    "('the beer was good.', 'pos'),\n",
    "('I do not enjoy my job', 'neg'),\n",
    "(\"I ain't feeling dandy today.\", 'neg'),\n",
    "(\"I feel amazing!\", 'pos'),\n",
    "('Gary is a friend of mine.', 'pos'),\n",
    "(\"I can't believe I'm doing this.\", 'neg')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Naive Bayes classifier\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classify text\n",
    "cl.classify(\"This is an amazing library!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dist = cl.prob_classify(\"This one's a doozy.\")\n",
    "prob_dist.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability of the text being positive.\n",
    "round(prob_dist.prob(\"pos\"), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability of the text being negative.\n",
    "round(prob_dist.prob(\"neg\"), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "blob = TextBlob(\"The beer is good. But the hangover is horrible.\", classifier=cl)\n",
    "blob.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The beer is good.\n",
      "pos\n",
      "But the hangover is horrible.\n",
      "neg\n"
     ]
    }
   ],
   "source": [
    "for s in blob.sentences:\n",
    "    print(s)\n",
    "    print(s.classify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "            contains(my) = True              neg : pos    =      1.7 : 1.0\n",
      "            contains(an) = False             neg : pos    =      1.6 : 1.0\n",
      "             contains(I) = True              neg : pos    =      1.4 : 1.0\n",
      "             contains(I) = False             pos : neg    =      1.4 : 1.0\n",
      "            contains(my) = False             pos : neg    =      1.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.show_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the classifier with enw training data.\n",
    "new_data = [('She is my best friend.', 'pos'),\n",
    "(\"I'm happy to have a new friend.\", 'pos'),\n",
    "(\"Stay thirsty, my friend.\", 'pos'),\n",
    "(\"He ain't from around here.\", 'neg')]\n",
    "cl.update(new_data)\n",
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence polarity:\n",
      "Sentence 1:   0.060\n",
      "Sentence 2:  -0.342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextBlob(\"The Blob的名義威脅一直令我震驚，因為它是終極電影\n",
       "怪物：一種無法滿足的飢餓，變形蟲般的物質，能夠穿透\n",
       "幾乎任何有保障的能力-就像一位注定要死的醫生一樣\n",
       "形容它“在接觸時吸收肉。\n",
       "該死的與明膠的比較是該死的，這是最多的概念\n",
       "毀滅性的潛在後果，與灰色的情況不謀而合\n",
       "技術理論家提出的擔心\n",
       "人工智能猖ramp。\")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text = '''\n",
    "The titular threat of The Blob has always struck me as the ultimate movie\n",
    "monster: an insatiably hungry, amoeba-like mass able to penetrate\n",
    "virtually any safeguard, capable of--as a doomed doctor chillingly\n",
    "describes it--\"assimilating flesh on contact.\n",
    "Snide comparisons to gelatin be damned, it's a concept with the most\n",
    "devastating of potential consequences, not unlike the grey goo scenario\n",
    "proposed by technological theorists fearful of\n",
    "artificial intelligence run rampant.\n",
    "'''\n",
    "\n",
    "blob = TextBlob(text)\n",
    "blob.tags           # [('The', 'DT'), ('titular', 'JJ'),\n",
    "                    #  ('threat', 'NN'), ('of', 'IN'), ...]\n",
    "\n",
    "blob.noun_phrases   # WordList(['titular threat', 'blob',\n",
    "                    #            'ultimate movie monster',\n",
    "                    #            'amoeba-like mass', ...])\n",
    "\n",
    "i = 1\n",
    "print(\"Sentence polarity:\")\n",
    "for sentence in blob.sentences:\n",
    "    print(\"Sentence %d: %7.3f\" % (i, sentence.sentiment.polarity))\n",
    "    i = i + 1\n",
    "# 0.060\n",
    "# -0.341\n",
    "\n",
    "blob.translate(to=\"zh-TW\")  # 'La amenaza titular de The Blob...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6 + Pyspark(Spark 2.2.0)",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
