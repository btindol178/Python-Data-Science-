{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve minutes</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>churnf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total day minutes  total day calls  total day charge  total eve minutes  \\\n",
       "0              265.1              110             45.07              197.4   \n",
       "1              161.6              123             27.47              195.5   \n",
       "2              243.4              114             41.38              121.2   \n",
       "3              299.4               71             50.90               61.9   \n",
       "4              166.7              113             28.34              148.3   \n",
       "\n",
       "   total eve calls  total eve charge  total night minutes  total night calls  \\\n",
       "0               99             16.78                244.7                 91   \n",
       "1              103             16.62                254.4                103   \n",
       "2              110             10.30                162.6                104   \n",
       "3               88              5.26                196.9                 89   \n",
       "4              122             12.61                186.9                121   \n",
       "\n",
       "   total night charge  total intl minutes  churnf  \n",
       "0               11.01                10.0       0  \n",
       "1               11.45                13.7       0  \n",
       "2                7.32                12.2       0  \n",
       "3                8.86                 6.6       0  \n",
       "4                8.41                10.1       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"CHURNF.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"churnf\"]]\n",
    "X = df[[\"total day minutes\", \"total day calls\",\"total eve minutes\",\"total eve calls\",\"total day charge\",\"total eve charge\",\"total night minutes\",\"total night calls\",\"total night charge\",\"total intl minutes\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and test sets\n",
    "X_train,X_test,y_train,y_test= train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the XGBClassifier: xg_cl\n",
    "xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=10, seed=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=123, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, seed=123, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the classifier to the training set\n",
    "xg_cl.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test set: preds\n",
    "preds = xg_cl.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Baggign Classifier: 0.874\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and print test-set accuracy\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print('Accuracy of Baggign Classifier: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation with DTMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DMatrix from X and y: churn_dmatrix\n",
    "churn_dmatrix = xgb.DMatrix(data=X, label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter dictionary: params\n",
    "params = {\"objective\":\"reg:logistic\", \"max_depth\":3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation: cv_results\n",
    "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, \n",
    "                    nfold=3, num_boost_round=5, \n",
    "                    metrics=\"error\", as_pandas=True, seed=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-error-mean  train-error-std  test-error-mean  test-error-std\n",
      "0          0.118512         0.003414         0.128713        0.006736\n",
      "1          0.115512         0.003681         0.127213        0.003625\n",
      "2          0.112811         0.003125         0.125112        0.006364\n",
      "3          0.112511         0.005052         0.125712        0.004667\n",
      "4          0.111011         0.004064         0.124513        0.008358\n"
     ]
    }
   ],
   "source": [
    "# Print cv_results\n",
    "print(cv_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8754873333333333\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy\n",
    "print(((1-cv_results[\"test-error-mean\"]).iloc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
      "0        0.713821       0.021153       0.684742      0.005078\n",
      "1        0.737288       0.016528       0.710326      0.008923\n",
      "2        0.750878       0.010821       0.711638      0.017402\n",
      "3        0.760891       0.008871       0.719560      0.015057\n",
      "4        0.772847       0.007623       0.731231      0.008579\n",
      "0.7312313333333332\n"
     ]
    }
   ],
   "source": [
    "# Perform cross_validation: cv_results\n",
    "cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, \n",
    "                    nfold=3, num_boost_round=5, \n",
    "                    metrics=\"auc\", as_pandas=True, seed=123)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)\n",
    "\n",
    "# Print the AUC\n",
    "print((cv_results[\"test-auc-mean\"]).iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Remodeled</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>...</th>\n",
       "      <th>HouseStyle_1.5Unf</th>\n",
       "      <th>HouseStyle_1Story</th>\n",
       "      <th>HouseStyle_2.5Fin</th>\n",
       "      <th>HouseStyle_2.5Unf</th>\n",
       "      <th>HouseStyle_2Story</th>\n",
       "      <th>HouseStyle_SFoyer</th>\n",
       "      <th>HouseStyle_SLvl</th>\n",
       "      <th>PavedDrive_P</th>\n",
       "      <th>PavedDrive_Y</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60           65     8450            7            5       2003   \n",
       "1          20           80     9600            6            8       1976   \n",
       "2          60           68    11250            7            5       2001   \n",
       "3          70           60     9550            7            5       1915   \n",
       "4          60           84    14260            8            5       2000   \n",
       "\n",
       "   Remodeled  GrLivArea  BsmtFullBath  BsmtHalfBath  ...  HouseStyle_1.5Unf  \\\n",
       "0          0       1710             1             0  ...                  0   \n",
       "1          0       1262             0             1  ...                  0   \n",
       "2          1       1786             1             0  ...                  0   \n",
       "3          1       1717             1             0  ...                  0   \n",
       "4          0       2198             1             0  ...                  0   \n",
       "\n",
       "   HouseStyle_1Story  HouseStyle_2.5Fin  HouseStyle_2.5Unf  HouseStyle_2Story  \\\n",
       "0                  0                  0                  0                  1   \n",
       "1                  1                  0                  0                  0   \n",
       "2                  0                  0                  0                  1   \n",
       "3                  0                  0                  0                  1   \n",
       "4                  0                  0                  0                  1   \n",
       "\n",
       "   HouseStyle_SFoyer  HouseStyle_SLvl  PavedDrive_P  PavedDrive_Y  SalePrice  \n",
       "0                  0                0             0             1     208500  \n",
       "1                  0                0             0             1     181500  \n",
       "2                  0                0             0             1     223500  \n",
       "3                  0                0             0             1     140000  \n",
       "4                  0                0             0             1     250000  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"ameshousingpricespreprocessed.csv\")\n",
    "df2.head(5)\n",
    "#list(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2[[\"SalePrice\"]]\n",
    "X = df2[[\"MSSubClass\",\n",
    " \"LotFrontage\",\n",
    " \"LotArea\",\n",
    " \"OverallQual\",\n",
    " \"OverallCond\",\n",
    " \"YearBuilt\",\n",
    " \"Remodeled\",\n",
    " \"GrLivArea\",\n",
    " \"BsmtFullBath\",\n",
    " \"BsmtHalfBath\",\n",
    " \"FullBath\",\n",
    " \"HalfBath\",\n",
    " \"BedroomAbvGr\",\n",
    " \"Fireplaces\",\n",
    " \"GarageArea\",\n",
    " \"MSZoning_FV\",\n",
    " \"MSZoning_RH\",\n",
    " \"MSZoning_RL\",\n",
    " \"MSZoning_RM\",\n",
    " \"Neighborhood_Blueste\",\n",
    " \"Neighborhood_BrDale\",\n",
    " \"Neighborhood_BrkSide\",\n",
    " \"Neighborhood_ClearCr\",\n",
    " \"Neighborhood_CollgCr\",\n",
    " \"Neighborhood_Crawfor\",\n",
    " \"Neighborhood_Edwards\",\n",
    " \"Neighborhood_Gilbert\",\n",
    " \"Neighborhood_IDOTRR\",\n",
    " \"Neighborhood_MeadowV\",\n",
    " \"Neighborhood_Mitchel\",\n",
    " \"Neighborhood_NAmes\",\n",
    " \"Neighborhood_NPkVill\",\n",
    " \"Neighborhood_NWAmes\",\n",
    " \"Neighborhood_NoRidge\",\n",
    " \"Neighborhood_NridgHt\",\n",
    " \"Neighborhood_OldTown\",\n",
    " \"Neighborhood_SWISU\",\n",
    " \"Neighborhood_Sawyer\",\n",
    " \"Neighborhood_SawyerW\",\n",
    " \"Neighborhood_Somerst\",\n",
    " \"Neighborhood_StoneBr\",\n",
    " \"Neighborhood_Timber\",\n",
    " \"Neighborhood_Veenker\",\n",
    " \"BldgType_2fmCon\",\n",
    " \"BldgType_Duplex\",\n",
    " \"BldgType_Twnhs\",\n",
    " \"BldgType_TwnhsE\",\n",
    " \"HouseStyle_1.5Unf\",\n",
    " \"HouseStyle_1Story\",\n",
    " \"HouseStyle_2.5Fin\",\n",
    " \"HouseStyle_2.5Unf\",\n",
    " \"HouseStyle_2Story\",\n",
    " \"HouseStyle_SFoyer\",\n",
    " \"HouseStyle_SLvl\",\n",
    " \"PavedDrive_P\",\n",
    " \"PavedDrive_Y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the XGBRegressor: xg_reg\n",
    "xg_reg = xgb.XGBRegressor(objective=\"reg:linear\", n_estimators=10, seed=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:50:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:50:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=10, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:linear', random_state=123, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=123, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the regressor to the training set\n",
    "xg_reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test set: preds\n",
    "preds = xg_reg.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 28106.46\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, preds)**(1/2)\n",
    "\n",
    "# print the test rmse\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:51:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:51:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# Convert the training and testing sets into DMatrixes: DM_train, DM_test\n",
    "DM_train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "DM_test =  xgb.DMatrix(data=X_test, label=y_test)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"booster\":\"gblinear\", \"objective\":\"reg:linear\"}\n",
    "\n",
    "# Train the model: xg_reg\n",
    "xg_reg = xgb.train(params = params, dtrain=DM_train, num_boost_round=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels of the test set: preds\n",
    "preds = xg_reg.predict(DM_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 44495.71\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, preds)**(1/2)\n",
    "\n",
    "# print the test rmse\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:53:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:53:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:53:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:53:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":4}\n",
    "\n",
    "# Perform cross-validation: cv_results\n",
    "cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=4, num_boost_round=5, metrics=\"rmse\", as_pandas=True, seed=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
      "0    141767.531250      429.448328   142980.433594    1193.789595\n",
      "1    102832.542969      322.468976   104891.392578    1223.157953\n",
      "2     75872.617188      266.473250    79478.937500    1601.344539\n",
      "3     57245.650391      273.625908    62411.924805    2220.148314\n",
      "4     44401.295899      316.422824    51348.281250    2963.379118\n",
      "4    51348.28125\n",
      "Name: test-rmse-mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print cv_results\n",
    "print(cv_results)\n",
    "\n",
    "# Extract and print final round boosting round metric\n",
    "print((cv_results[\"test-rmse-mean\"]).tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:53:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:53:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:53:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:53:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":4}\n",
    "\n",
    "# Perform cross-validation: cv_results\n",
    "cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=4, num_boost_round=5, metrics=\"mae\", as_pandas=True, seed=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-mae-mean  train-mae-std  test-mae-mean  test-mae-std\n",
      "0   127343.572266     668.344199  127633.988282   2403.993968\n",
      "1    89770.056641     456.949630   90122.498047   2107.907095\n",
      "2    63580.791016     263.405561   64278.559571   1887.564512\n",
      "3    45633.141602     151.886070   46819.167969   1459.813514\n",
      "4    33587.092774      86.999470   35670.649414   1140.607637\n",
      "4    35670.649414\n",
      "Name: test-mae-mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print cv_results\n",
    "print(cv_results)\n",
    "\n",
    "# Extract and print final round boosting round metric\n",
    "print((cv_results[\"test-mae-mean\"]).tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGULARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:54:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:54:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:54:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:54:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:54:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:54:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "reg_params = [1, 10, 100]\n",
    "\n",
    "# Create the initial parameter dictionary for varying l2 strength: params\n",
    "params = {\"objective\":\"reg:linear\",\"max_depth\":3}\n",
    "\n",
    "# Create an empty list for storing rmses as a function of l2 complexity\n",
    "rmses_l2 = []\n",
    "\n",
    "# Iterate over reg_params\n",
    "for reg in reg_params:\n",
    "\n",
    "    # Update l2 strength\n",
    "    params[\"lambda\"] = reg\n",
    "    \n",
    "    # Pass this updated param dictionary into cv\n",
    "    cv_results_rmse = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2, num_boost_round=5, metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    # Append best rmse (final round) to rmses_l2\n",
    "    rmses_l2.append(cv_results_rmse[\"test-rmse-mean\"].tail(1).values[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best rmse as a function of l2:\n",
      "    l2          rmse\n",
      "0    1  52275.355469\n",
      "1   10  57746.066406\n",
      "2  100  76624.628907\n"
     ]
    }
   ],
   "source": [
    "# Look at best rmse per l2 param\n",
    "print(\"Best rmse as a function of l2:\")\n",
    "print(pd.DataFrame(list(zip(reg_params, rmses_l2)), columns=[\"l2\",\"rmse\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:58:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:58:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":2}\n",
    "\n",
    "# Train the model: xg_reg\n",
    "xg_reg = xgb.train(params=params, dtrain=housing_dmatrix, num_boost_round=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first tree\n",
    "xgb.plot_tree(xg_reg, num_trees=0)\n",
    "plt.show()\n",
    "\n",
    "# Plot the fifth tree\n",
    "xgb.plot_tree(xg_reg, num_trees=4)\n",
    "plt.show()\n",
    "\n",
    "# Plot the last tree sideways\n",
    "xgb.plot_tree(xg_reg, num_trees=9, rankdir='LR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:00:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:00:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":4}\n",
    "\n",
    "# Train the model: xg_reg\n",
    "xg_reg = xgb.train(params=params, dtrain=housing_dmatrix, num_boost_round=10)\n",
    "\n",
    "# Plot the feature importances\n",
    "xgb.plot_importance(xg_reg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUNING\n",
    "the number of boosting rounds (number of trees you build) impacts the out-of-sample performance of your XGBoost model. You'll use xgb.cv() inside a for loop and build one model per num_boost_round parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:32:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:32:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:32:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:32:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:32:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:32:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:32:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:32:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:32:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "   num_boosting_rounds          rmse\n",
      "0                    5  50903.300782\n",
      "1                   10  34774.192709\n",
      "2                   15  32895.096354\n"
     ]
    }
   ],
   "source": [
    "# Create the DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary for each tree: params \n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":3}\n",
    "\n",
    "# Create list of number of boosting rounds\n",
    "num_rounds = [5, 10, 15]\n",
    "\n",
    "# Empty list to store final round rmse per XGBoost model\n",
    "final_rmse_per_round = []\n",
    "\n",
    "# Iterate over num_rounds and build one model per num_boost_round parameter\n",
    "for curr_num_rounds in num_rounds:\n",
    "\n",
    "    # Perform cross-validation: cv_results\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=3, num_boost_round=curr_num_rounds, metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    # Append final round RMSE\n",
    "    final_rmse_per_round.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "num_rounds_rmses = list(zip(num_rounds, final_rmse_per_round))\n",
    "print(pd.DataFrame(num_rounds_rmses,columns=[\"num_boosting_rounds\",\"rmse\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can very easily have XGBoost automatically select the number of boosting rounds for you within xgb.cv(). This is done using a technique called early stopping.\n",
    "\n",
    "Early stopping works by testing the XGBoost model after every boosting round against a hold-out dataset and stopping the creation of additional boosting rounds (thereby finishing training of the model early) if the hold-out metric (\"rmse\" in our case) does not improve for a given number of rounds. Here you will use the early_stopping_rounds parameter in xgb.cv() \n",
    "with a large possible number of boosting rounds (50). Bear in mind that if the holdout metric continuously improves up through when num_boost_rounds is reached, then early stopping does not occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:33:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:33:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:33:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
      "0     141871.630208      403.632409   142640.645833     705.565658\n",
      "1     103057.031250       73.772931   104907.666667     111.114933\n",
      "2      75975.963542      253.734987    79262.059896     563.766991\n",
      "3      57420.528646      521.655155    61620.135417    1087.690754\n",
      "4      44552.955729      544.169200    50437.562500    1846.448017\n",
      "5      35763.950521      681.797429    43035.660156    2034.469858\n",
      "6      29861.464844      769.570645    38600.881511    2169.800969\n",
      "7      25994.673177      756.520694    36071.817708    2109.795430\n",
      "8      23306.833333      759.237086    34383.184896    1934.546688\n",
      "9      21459.768880      745.624404    33509.141927    1887.377720\n",
      "10     20148.720703      749.612103    32916.806641    1850.893136\n",
      "11     19215.382161      641.388291    32197.834635    1734.458508\n",
      "12     18627.388021      716.257152    31770.853516    1802.155409\n",
      "13     17960.695312      557.043498    31482.782552    1779.123767\n",
      "14     17559.736979      631.412969    31389.990234    1892.319927\n",
      "15     17205.713867      590.172770    31302.882162    1955.165902\n",
      "16     16876.570964      703.631690    31234.058594    1880.705796\n",
      "17     16597.662760      703.676764    31318.348958    1828.861483\n",
      "18     16330.461589      607.273497    31323.634115    1775.908526\n",
      "19     16005.973307      520.471073    31204.136068    1739.077074\n",
      "20     15814.301432      518.604477    31089.862630    1756.020157\n",
      "21     15493.405924      505.616658    31047.996094    1624.673955\n",
      "22     15270.734049      502.019652    31056.916016    1668.042813\n",
      "23     15086.382487      503.912747    31024.985026    1548.985856\n",
      "24     14917.607747      486.206362    30983.684896    1663.128699\n",
      "25     14709.588868      449.666844    30989.475261    1686.666560\n",
      "26     14457.286458      376.787206    30952.113281    1613.172049\n",
      "27     14185.566406      383.102876    31066.902344    1648.534310\n",
      "28     13934.067383      473.465256    31095.639974    1709.224745\n",
      "29     13749.646159      473.671021    31103.888021    1778.879153\n",
      "30     13549.836914      454.898923    30976.086589    1744.515448\n",
      "31     13413.484375      399.603774    30938.469401    1746.052597\n",
      "32     13275.915364      415.408340    30931.000651    1772.468466\n",
      "33     13085.878255      493.792778    30929.055990    1765.539740\n",
      "34     12947.181315      517.790039    30890.631510    1786.509640\n",
      "35     12846.027669      547.732453    30884.494141    1769.728223\n",
      "36     12702.378581      505.523563    30833.542318    1691.002985\n",
      "37     12532.244466      508.298083    30856.688802    1771.446777\n",
      "38     12384.054362      536.225108    30818.016927    1782.784718\n",
      "39     12198.443685      545.165137    30839.391927    1847.327847\n",
      "40     12054.583333      508.841412    30776.966146    1912.781920\n",
      "41     11897.036784      477.177622    30794.701172    1919.675316\n",
      "42     11756.221680      502.992419    30780.954427    1906.819550\n",
      "43     11618.846029      519.838297    30783.755859    1951.259316\n",
      "44     11484.080404      578.428621    30776.731120    1953.446310\n",
      "45     11356.552734      565.368794    30758.543620    1947.456345\n",
      "46     11193.557292      552.298848    30729.971354    1985.698867\n",
      "47     11071.315755      604.089261    30732.664062    1966.998275\n",
      "48     10950.778320      574.862779    30712.240886    1957.751118\n",
      "49     10824.865560      576.666458    30720.854818    1950.511520\n"
     ]
    }
   ],
   "source": [
    "# Create your housing DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "# Create the parameter dictionary for each tree: params\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":4}\n",
    "\n",
    "# Perform cross-validation with early stopping: cv_results\n",
    "cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=3, num_boost_round=50, early_stopping_rounds=10, metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "\n",
    "# Print cv_results\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning ETA or (learning rate)\n",
    "You'll begin by tuning the \"eta\", also known as the learning rate.\n",
    "\n",
    "The learning rate in XGBoost is a parameter that can range between 0 and 1, with higher values of \"eta\" penalizing feature weights more strongly, causing much stronger regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:35:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:35:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:35:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:35:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:35:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:35:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:35:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:35:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:35:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "     eta      best_rmse\n",
      "0  0.001  195736.401042\n",
      "1  0.010  179932.182292\n",
      "2  0.100   79759.414063\n"
     ]
    }
   ],
   "source": [
    "# Create your housing DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Create the parameter dictionary for each tree (boosting round)\n",
    "params = {\"objective\":\"reg:linear\", \"max_depth\":3}\n",
    "\n",
    "# Create list of eta values and empty list to store final round rmse per xgboost model\n",
    "eta_vals = [0.001, 0.01, 0.1]\n",
    "best_rmse = []\n",
    "\n",
    "# Systematically vary the eta\n",
    "for curr_val in eta_vals:\n",
    "\n",
    "    params[\"eta\"] = curr_val\n",
    "    \n",
    "    # Perform cross-validation: cv_results\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=3,\n",
    "                        num_boost_round=10, early_stopping_rounds=5,\n",
    "                        metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    # Append the final round rmse to best_rmse\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "print(pd.DataFrame(list(zip(eta_vals, best_rmse)), columns=[\"eta\",\"best_rmse\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning max depth \n",
    "Smaller values will lead to shallower trees, and larger values to deeper trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:37:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:37:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:37:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:37:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:37:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:37:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:37:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:37:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "   max_depth     best_rmse\n",
      "0          2  37957.468750\n",
      "1          5  35596.599610\n",
      "2         10  36065.546875\n",
      "3         20  36739.578125\n"
     ]
    }
   ],
   "source": [
    "# Create your housing DMatrix: housing_dmatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "# Create the parameter dictionary\n",
    "params = {\"objective\":\"reg:linear\"}\n",
    "\n",
    "# Create list of max_depth values\n",
    "max_depths = [2, 5, 10, 20]\n",
    "best_rmse = []\n",
    "\n",
    "# Systematically vary the max_depth\n",
    "for curr_val in max_depths:\n",
    "\n",
    "    params[\"max_depth\"] = curr_val\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2,\n",
    "                 num_boost_round=10, early_stopping_rounds=5,\n",
    "                 metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    # Append the final round rmse to best_rmse\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "print(pd.DataFrame(list(zip(max_depths, best_rmse)),columns=[\"max_depth\",\"best_rmse\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning colsample_bytree\n",
    "Now, it's time to tune \"colsample_bytree\". You've already seen this if you've ever worked with scikit-learn's RandomForestClassifier or RandomForestRegressor, where it just was called max_features. In both xgboost and sklearn, this parameter (although named differently) simply specifies the fraction of features to choose from at every split in a given tree. In xgboost, colsample_bytree must be specified as a float between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:39:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:39:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:39:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:39:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:39:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:39:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:39:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:39:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.1.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "   colsample_bytree     best_rmse\n",
      "0               0.1  40918.115235\n",
      "1               0.5  35813.906250\n",
      "2               0.8  35995.679688\n",
      "3               1.0  35836.044922\n"
     ]
    }
   ],
   "source": [
    "# Create your housing DMatrix\n",
    "housing_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "# Create the parameter dictionary\n",
    "params={\"objective\":\"reg:linear\",\"max_depth\":3}\n",
    "\n",
    "# Create list of hyperparameter values\n",
    "colsample_bytree_vals = [0.1, 0.5, 0.8, 1]\n",
    "best_rmse = []\n",
    "\n",
    "# Systematically vary the hyperparameter value \n",
    "for curr_val in colsample_bytree_vals:\n",
    "\n",
    "    params[\"colsample_bytree\"] = curr_val\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2,\n",
    "                 num_boost_round=10, early_stopping_rounds=5,\n",
    "                 metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "    \n",
    "    # Append the final round rmse to best_rmse\n",
    "    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n",
    "\n",
    "# Print the resultant DataFrame\n",
    "print(pd.DataFrame(list(zip(colsample_bytree_vals, best_rmse)), columns=[\"colsample_bytree\",\"best_rmse\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search with XGBoost\n",
    "Now that you've learned how to tune parameters individually with XGBoost, let's take your parameter tuning to the next level by using scikit-learn's GridSearch and RandomizedSearch capabilities with internal cross-validation using the GridSearchCV and RandomizedSearchCV functions. You will use these to find the best model exhaustively from a collection of possible parameter values across multiple parameters simultaneously. Let's get to work, starting with GridSearchCV!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'colsample_bytree': 0.3, 'max_depth': 5, 'n_estimators': 50}\n",
      "Lowest RMSE found:  28986.18703093561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    2.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid: gbm_param_grid\n",
    "gbm_param_grid = {\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    "    'n_estimators': [50],\n",
    "    'max_depth': [2, 5]\n",
    "}\n",
    "\n",
    "# Instantiate the regressor: gbm\n",
    "gbm = xgb.XGBRegressor()\n",
    "\n",
    "# Perform grid search: grid_mse\n",
    "grid_mse = GridSearchCV(estimator=gbm, param_grid=gbm_param_grid,\n",
    "                        scoring='neg_mean_squared_error', cv=4, verbose=1)\n",
    "grid_mse.fit(X, y)\n",
    "\n",
    "# Print the best parameters and lowest RMSE\n",
    "print(\"Best parameters found: \", grid_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random search with XGBoost\n",
    "Often, GridSearchCV can be really time consuming, so in practice, you may want to use RandomizedSearchCV instead, as you will do in this exercise. The good news is you only have to make a few modifications to your GridSearchCV code to do RandomizedSearchCV. The key difference is you have to specify a param_distributions parameter instead of a param_grid parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'n_estimators': 25, 'max_depth': 4}\n",
      "Lowest RMSE found:  29998.4522530019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    2.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Create the parameter grid: gbm_param_grid \n",
    "gbm_param_grid = {\n",
    "    'n_estimators': [25],\n",
    "    'max_depth': range(2, 12)\n",
    "}\n",
    "\n",
    "# Instantiate the regressor: gbm\n",
    "gbm = xgb.XGBRegressor(n_estimators=10)\n",
    "\n",
    "# Perform random search: grid_mse\n",
    "randomized_mse = RandomizedSearchCV(estimator=gbm, param_distributions=gbm_param_grid,\n",
    "                                    n_iter=5, scoring='neg_mean_squared_error', cv=4, verbose=1)\n",
    "randomized_mse.fit(X, y)\n",
    "\n",
    "# Print the best parameters and lowest RMSE\n",
    "print(\"Best parameters found: \",randomized_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(randomized_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPELINES FOR XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Remodeled</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>...</th>\n",
       "      <th>HouseStyle_1.5Unf</th>\n",
       "      <th>HouseStyle_1Story</th>\n",
       "      <th>HouseStyle_2.5Fin</th>\n",
       "      <th>HouseStyle_2.5Unf</th>\n",
       "      <th>HouseStyle_2Story</th>\n",
       "      <th>HouseStyle_SFoyer</th>\n",
       "      <th>HouseStyle_SLvl</th>\n",
       "      <th>PavedDrive_P</th>\n",
       "      <th>PavedDrive_Y</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60           65     8450            7            5       2003   \n",
       "1          20           80     9600            6            8       1976   \n",
       "2          60           68    11250            7            5       2001   \n",
       "3          70           60     9550            7            5       1915   \n",
       "4          60           84    14260            8            5       2000   \n",
       "\n",
       "   Remodeled  GrLivArea  BsmtFullBath  BsmtHalfBath  ...  HouseStyle_1.5Unf  \\\n",
       "0          0       1710             1             0  ...                  0   \n",
       "1          0       1262             0             1  ...                  0   \n",
       "2          1       1786             1             0  ...                  0   \n",
       "3          1       1717             1             0  ...                  0   \n",
       "4          0       2198             1             0  ...                  0   \n",
       "\n",
       "   HouseStyle_1Story  HouseStyle_2.5Fin  HouseStyle_2.5Unf  HouseStyle_2Story  \\\n",
       "0                  0                  0                  0                  1   \n",
       "1                  1                  0                  0                  0   \n",
       "2                  0                  0                  0                  1   \n",
       "3                  0                  0                  0                  1   \n",
       "4                  0                  0                  0                  1   \n",
       "\n",
       "   HouseStyle_SFoyer  HouseStyle_SLvl  PavedDrive_P  PavedDrive_Y  SalePrice  \n",
       "0                  0                0             0             1     208500  \n",
       "1                  0                0             0             1     181500  \n",
       "2                  0                0             0             1     223500  \n",
       "3                  0                0             0             1     140000  \n",
       "4                  0                0             0             1     250000  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ameshousingpricespreprocessed.csv\")\n",
    "df.head(5)\n",
    "#list(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Fill missing values with 0\n",
    "df.LotFrontage = df.LotFrontage.fillna(0)\n",
    "\n",
    "# Create a boolean mask for categorical columns\n",
    "categorical_mask = (df.dtypes == object)\n",
    "\n",
    "# Get list of categorical column names\n",
    "categorical_columns = df.columns[categorical_mask].tolist()\n",
    "\n",
    "# Print the head of the categorical columns\n",
    "print(df[categorical_columns].head())\n",
    "\n",
    "# Create LabelEncoder object: le\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply LabelEncoder to categorical columns\n",
    "df[categorical_columns] = df[categorical_columns].apply(lambda x: le.fit_transform(x))\n",
    "\n",
    "# Print the head of the LabelEncoded categorical columns\n",
    "print(df[categorical_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create OneHotEncoder: ohe\n",
    "ohe = OneHotEncoder(categorical_features=categorical_mask, sparse=False)\n",
    "\n",
    "# Apply OneHotEncoder to categorical columns - output is no longer a dataframe: df_encoded\n",
    "df_encoded = ohe.fit_transform(df)\n",
    "\n",
    "# Print first 5 rows of the resulting dataset - again, this will no longer be a pandas dataframe\n",
    "print(df_encoded[:5, :])\n",
    "\n",
    "# Print the shape of the original DataFrame\n",
    "print(df.shape)\n",
    "\n",
    "# Print the shape of the transformed array\n",
    "print(df_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DictVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# Convert df into a dictionary: df_dict\n",
    "df_dict = df.to_dict(\"records\")\n",
    "\n",
    "# Create the DictVectorizer object: dv\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# Apply dv on df: df_encoded\n",
    "df_encoded = dv.fit_transform(df_dict)\n",
    "\n",
    "# Print the resulting first five rows\n",
    "print(df_encoded[:5,:])\n",
    "\n",
    "# Print the vocabulary\n",
    "print(dv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Fill LotFrontage missing values with 0\n",
    "X.LotFrontage = X.LotFrontage.fillna(0)\n",
    "\n",
    "# Setup the pipeline steps: steps\n",
    "steps = [(\"ohe_onestep\", DictVectorizer(sparse=False)),\n",
    "         (\"xgb_model\", xgb.XGBRegressor())]\n",
    "\n",
    "# Create the pipeline: xgb_pipeline\n",
    "xgb_pipeline = Pipeline(steps)\n",
    "\n",
    "# Fit the pipeline\n",
    "xgb_pipeline.fit(X.to_dict(\"records\"), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Fill LotFrontage missing values with 0\n",
    "X.LotFrontage = X.LotFrontage.fillna(0)\n",
    "\n",
    "# Setup the pipeline steps: steps\n",
    "steps = [(\"ohe_onestep\", DictVectorizer(sparse=False)),\n",
    "         (\"xgb_model\", xgb.XGBRegressor(max_depth=2, objective=\"reg:linear\"))]\n",
    "\n",
    "# Create the pipeline: xgb_pipeline\n",
    "xgb_pipeline = Pipeline(steps)\n",
    "\n",
    "# Cross-validate the model\n",
    "cross_val_scores = cross_val_score(xgb_pipeline, X.to_dict(\"records\"), y, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "# Print the 10-fold RMSE\n",
    "print(\"10-fold RMSE: \", np.mean(np.sqrt(np.abs(cross_val_scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn_pandas import CategoricalImputer\n",
    "\n",
    "# Check number of nulls in each feature column\n",
    "nulls_per_column = X.isnull().sum()\n",
    "print(nulls_per_column)\n",
    "\n",
    "# Create a boolean mask for categorical columns\n",
    "categorical_feature_mask = X.dtypes == object\n",
    "\n",
    "# Get list of categorical column names\n",
    "categorical_columns = X.columns[categorical_feature_mask].tolist()\n",
    "\n",
    "# Get list of non-categorical column names\n",
    "non_categorical_columns = X.columns[~categorical_feature_mask].tolist()\n",
    "\n",
    "# Apply numeric imputer\n",
    "numeric_imputation_mapper = DataFrameMapper(\n",
    "                                            [([numeric_feature],Imputer(strategy=\"median\")) for numeric_feature in non_categorical_columns],\n",
    "                                            input_df=True,\n",
    "                                            df_out=True\n",
    "                                           )\n",
    "\n",
    "# Apply categorical imputer\n",
    "categorical_imputation_mapper = DataFrameMapper(\n",
    "                                                [(category_feature, CategoricalImputer()) for category_feature in categorical_columns],\n",
    "                                                input_df=True,\n",
    "                                                df_out=True\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import FeatureUnion\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Combine the numeric and categorical transformations\n",
    "numeric_categorical_union = FeatureUnion([\n",
    "                                          (\"num_mapper\", numeric_imputation_mapper),\n",
    "                                          (\"cat_mapper\", categorical_imputation_mapper)\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>48</th>\n",
       "      <th>80</th>\n",
       "      <th>1.02</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>?</th>\n",
       "      <th>normal</th>\n",
       "      <th>notpresent</th>\n",
       "      <th>notpresent.1</th>\n",
       "      <th>121</th>\n",
       "      <th>...</th>\n",
       "      <th>44</th>\n",
       "      <th>7800</th>\n",
       "      <th>5.2</th>\n",
       "      <th>yes</th>\n",
       "      <th>yes.1</th>\n",
       "      <th>no</th>\n",
       "      <th>good</th>\n",
       "      <th>no.1</th>\n",
       "      <th>no.2</th>\n",
       "      <th>ckd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>1.02</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>6000</td>\n",
       "      <td>?</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>80</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>7500</td>\n",
       "      <td>?</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>70</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>6700</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>80</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>7300</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>1.015</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>7800</td>\n",
       "      <td>4.4</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   48  80   1.02  1  0       ?    normal  notpresent notpresent.1  121  ...  \\\n",
       "0   7  50   1.02  4  0       ?    normal  notpresent   notpresent    ?  ...   \n",
       "1  62  80   1.01  2  3  normal    normal  notpresent   notpresent  423  ...   \n",
       "2  48  70  1.005  4  0  normal  abnormal     present   notpresent  117  ...   \n",
       "3  51  80   1.01  2  0  normal    normal  notpresent   notpresent  106  ...   \n",
       "4  60  90  1.015  3  0       ?         ?  notpresent   notpresent   74  ...   \n",
       "\n",
       "   44  7800  5.2  yes yes.1  no  good no.1 no.2  ckd  \n",
       "0  38  6000    ?   no    no  no  good   no   no  ckd  \n",
       "1  31  7500    ?   no   yes  no  poor   no  yes  ckd  \n",
       "2  32  6700  3.9  yes    no  no  poor  yes  yes  ckd  \n",
       "3  35  7300  4.6   no    no  no  good   no   no  ckd  \n",
       "4  39  7800  4.4  yes   yes  no  good  yes   no  ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kidney_data = pd.read_csv(\"chronic kidney disease.csv\")\n",
    "kidney_data.head(5)\n",
    "#list(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full pipeline\n",
    "pipeline = Pipeline([\n",
    "                     (\"featureunion\", numeric_categorical_union),\n",
    "                     (\"dictifier\", Dictifier()),\n",
    "                     (\"vectorizer\", DictVectorizer(sort=False)),\n",
    "                     (\"clf\", xgb.XGBClassifier(max_depth=3))\n",
    "                    ])\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_scores = cross_val_score(pipeline, kidney_data, y, scoring=\"roc_auc\", cv=3)\n",
    "\n",
    "# Print avg. AUC\n",
    "print(\"3-fold AUC: \", np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "gbm_param_grid = {\n",
    "    'clf__learning_rate': np.arange(.05, 1, .05),\n",
    "    'clf__max_depth': np.arange(3,10, 1),\n",
    "    'clf__n_estimators': np.arange(50, 200, 50)\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "randomized_roc_auc = RandomizedSearchCV(estimator=pipeline,\n",
    "                                        param_distributions=gbm_param_grid,\n",
    "                                        n_iter=2, scoring='roc_auc', cv=2, verbose=1)\n",
    "\n",
    "# Fit the estimator\n",
    "randomized_roc_auc.fit(X, y)\n",
    "\n",
    "# Compute metrics\n",
    "print(randomized_roc_auc.best_score_)\n",
    "print(randomized_roc_auc.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
