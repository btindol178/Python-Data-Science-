{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (sample with replacement) of original dataset to make many different samples for training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models and utility functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
      "0                 0.07871  ...         25.38          17.33           184.60   \n",
      "1                 0.05667  ...         24.99          23.41           158.80   \n",
      "2                 0.05999  ...         23.57          25.53           152.50   \n",
      "3                 0.09744  ...         14.91          26.50            98.87   \n",
      "4                 0.05883  ...         22.54          16.67           152.20   \n",
      "\n",
      "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   worst concave points  worst symmetry  worst fractal dimension  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "data_pd.columns = data.feature_names\n",
    "print(data_pd.head())\n",
    "# assign predictors and dependent to x and y and make dataframe\n",
    "X =data.data\n",
    "y = data.target\n",
    "df = pd.DataFrame(X, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "# Split data to 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify = y, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Baggign Classifier: 0.942\n"
     ]
    }
   ],
   "source": [
    "# instantiate a classification tree dt\n",
    "dt = DecisionTreeClassifier(max_depth = 4, min_samples_leaf = 0.16, random_state = SEED)\n",
    "\n",
    "# Instantiate Bagging Classifier bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=300, n_jobs=-1)\n",
    "\n",
    "\n",
    "# fit bc to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predict the test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate and print test-set accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of Baggign Classifier: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of Bag Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "# Split data to 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify = y, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a classification tree dt\n",
    "dt = DecisionTreeClassifier(max_depth = 4, min_samples_leaf = 0.16, random_state = SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Bagging Classifier bc\n",
    "# just change oob_score = True as a parameter\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=300,oob_score =True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit bc to the train set\n",
    "bc.fit(X_train,y_train)\n",
    "\n",
    "# predict the test set labels\n",
    "y_pred = bc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.936\n"
     ]
    }
   ],
   "source": [
    "# evaluate test set accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# extract the OOB accracy from bc\n",
    "oob_accuracy = bc.oob_score_\n",
    "\n",
    "# print the test set accuracy \n",
    "print('Test set accuracy: {:.3f}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB accuracy: 0.925\n"
     ]
    }
   ],
   "source": [
    "# Print OOB accuracy\n",
    "print('OOB accuracy: {:.3f}'.format(oob_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  RANDOM FORESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USES RANDOM SAMPLES SAME SIZE AS TRAINING SET\n",
    "# EACH TREE TRAINED ON DIFFERENT SAMPLE (WITHOUT REPLACEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
       "0  18.0          8         307.0        130    3504          12.0          70   \n",
       "1  15.0          8         350.0        165    3693          11.5          70   \n",
       "2  18.0          8         318.0        150    3436          11.0          70   \n",
       "3  16.0          8         304.0        150    3433          12.0          70   \n",
       "4  17.0          8         302.0        140    3449          10.5          70   \n",
       "\n",
       "   origin                   car name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"cars.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"mpg\"]]\n",
    "X = df[[\"cylinders\", \"displacement\",\"weight\",\"acceleration\",\"model year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SEED for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Split the data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make random forest regressor\n",
    "rf = RandomForestRegressor(n_estimators = 400, min_samples_leaf=0.12, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blake\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# fit rf to the training set\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# predict the test set labels y_pred\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 3.19\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# print the test rmse\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize importance of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a pd.series of features importance\n",
    "importances_rf = pd.Series(rf.feature_importances_, index = X.columns)\n",
    "\n",
    "# sort importances_rf\n",
    "sorted_importances_rf = importances_rf.sort_values()\n",
    "\n",
    "# make horizontal bar plot\n",
    "sorted_importances_rf.plot(kind = 'barh', color = 'lightgreen'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOOSTING MANY WEEK LEARNERS ARE COMBINED TO FORM A STRONG LEARNER\n",
    "# BOOSTING IS TRAINING AN ENSEMBLE OF PREDICTORS SEQUENTIALLY AND EACH PREDICTOR TRIES TO CORRECT PREDECESSORS\n",
    "# GRADIENT BOOSTING IS ANOTHER\n",
    "# ADABOOST IS ADAPTIVE BOOSTING (CHANGING WEIGHTS OF TRAINING INSTANCES)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
      "0                 0.07871  ...         25.38          17.33           184.60   \n",
      "1                 0.05667  ...         24.99          23.41           158.80   \n",
      "2                 0.05999  ...         23.57          25.53           152.50   \n",
      "3                 0.09744  ...         14.91          26.50            98.87   \n",
      "4                 0.05883  ...         22.54          16.67           152.20   \n",
      "\n",
      "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   worst concave points  worst symmetry  worst fractal dimension  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "data_pd.columns = data.feature_names\n",
    "print(data_pd.head())\n",
    "# assign predictors and dependent to x and y and make dataframe\n",
    "X =data.data\n",
    "y = data.target\n",
    "df = pd.DataFrame(X, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "# Split data to 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify = y, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a classification tree dt\n",
    "dt = DecisionTreeClassifier(max_depth=1, random_state = SEED)\n",
    "\n",
    "# Instantiate ada\n",
    "ada = AdaBoostClassifier(base_estimator=dt, n_estimators=180, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ada to the training set\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Compute the probabilities of obtaining the positive class\n",
    "y_pred_proba = ada.predict_proba(X_test)[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Evaluate test-set roc_auc_score\n",
    "ada_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print('ROC AUC score: {:.2f}'.format(ada_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADIENT BOOSTING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cars.csv\")\n",
    "y = df[[\"mpg\"]]\n",
    "X = df[[\"cylinders\", \"displacement\",\"weight\",\"acceleration\",\"model year\"]]\n",
    "\n",
    "# Set SEED for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Split the data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a gradient boosting Regressor gbt\n",
    "gbt = GradientBoostingRegressor(n_estimators=300, max_depth = 1,random_state = SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE: 2.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blake\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# fit gbt to the trainingset\n",
    "gbt.fit(X_train,y_train)\n",
    "\n",
    "# predict the test set labels\n",
    "y_pred = gbt.predict(X_test)\n",
    "\n",
    "#evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# print the test set RMSE\n",
    "print('Test set RMSE: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stocastic Gradient Boosting (SGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting sometimes uses same split points and hyper perameters this can be exhaustive\n",
    "# SGB each tree is trained on a random subset of rows in training data\n",
    "# the samples are without replacement\n",
    "# features are ssampled without replacement when choosing split poings\n",
    "# this creates further diversity for ensemble adding more variance for ensemble of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuing with the Auto dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgbt = GradientBoostingRegressor(max_depth=1,subsample=0.8,max_features=0.2,n_estimators=300,random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blake\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# fit sgbt to the training set\n",
    "sgbt.fit(X_train, y_train)\n",
    "\n",
    "# predict the test set labels\n",
    "y_pred = sgbt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE: 2.68\n"
     ]
    }
   ],
   "source": [
    "# Evaluate test set RMSE rmse_test\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE: {:.2F}'.format(rmse_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Import roc_auc_score from sklearn.metrics \n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
      "0                 0.07871  ...         25.38          17.33           184.60   \n",
      "1                 0.05667  ...         24.99          23.41           158.80   \n",
      "2                 0.05999  ...         23.57          25.53           152.50   \n",
      "3                 0.09744  ...         14.91          26.50            98.87   \n",
      "4                 0.05883  ...         22.54          16.67           152.20   \n",
      "\n",
      "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   worst concave points  worst symmetry  worst fractal dimension  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "data_pd.columns = data.feature_names\n",
    "print(data_pd.head())\n",
    "# assign predictors and dependent to x and y and make dataframe\n",
    "X =data.data\n",
    "y = data.target\n",
    "df = pd.DataFrame(X, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "# Split data to 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify = y, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a classification tree dt\n",
    "dt = DecisionTreeClassifier(max_depth=1, random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define params_dt\n",
    "params_dt = {\n",
    "             'max_depth': [2, 3, 4],\n",
    "             'min_samples_leaf': [0.12, 0.14, 0.16, 0.18],\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=1,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=1, splitter='best'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 3, 4],\n",
       "                         'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate grid_dt\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring='roc_auc',\n",
    "                       cv=5,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "# fit gbt to the trainingset\n",
    "grid_dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set ROC AUC score: 0.959\n"
     ]
    }
   ],
   "source": [
    "# Extract the best estimator\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute test_roc_auc\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print test_roc_auc\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      " {'max_depth': 3, 'min_samples_leaf': 0.14}\n"
     ]
    }
   ],
   "source": [
    "# extract best hyperparameters from grid_dt\n",
    "best_hyperparams = grid_dt.best_params_\n",
    "print('Best hyperparameters:\\n', best_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Random forest for HPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
       "0  18.0          8         307.0        130    3504          12.0          70   \n",
       "1  15.0          8         350.0        165    3693          11.5          70   \n",
       "2  18.0          8         318.0        150    3436          11.0          70   \n",
       "3  16.0          8         304.0        150    3433          12.0          70   \n",
       "4  17.0          8         302.0        140    3449          10.5          70   \n",
       "\n",
       "   origin                   car name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "df = pd.read_csv(\"cars.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"mpg\"]]\n",
    "X = df[[\"cylinders\", \"displacement\",\"weight\",\"acceleration\",\"model year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SEED for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Split the data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dictionary 'params_rf'\n",
    "params_rf = {\n",
    "             'n_estimators': [100, 350, 500],\n",
    "             'max_features': ['log2', 'auto', 'sqrt'],\n",
    "             'min_samples_leaf': [2, 10, 30], \n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:   15.6s finished\n",
      "C:\\Users\\blake\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=0.12,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=400, n_jobs=None,\n",
       "                                             oob_score=False, random_state=1,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_features': ['log2', 'auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [2, 10, 30],\n",
       "                         'n_estimators': [100, 350, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make random forest regressor\n",
    "# make random forest regressor\n",
    "rf = RandomForestRegressor(n_estimators = 400, min_samples_leaf=0.12, random_state = SEED)\n",
    "\n",
    "# Instantiate grid_rf\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=3,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      " {'max_features': 'log2', 'min_samples_leaf': 2, 'n_estimators': 350}\n"
     ]
    }
   ],
   "source": [
    "# extract best hyper parameters from grid_rf\n",
    "best_hyperparams = grid_rf.best_params_\n",
    "\n",
    "print('Best hyperparameters:\\n', best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE of best model: 2.613\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_rf.best_estimator_\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute rmse_test\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test RMSE of best model: {:.3f}'.format(rmse_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
